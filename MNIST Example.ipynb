{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Handwritten Digit Recognition\n",
    "\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist) is often considered the [hello world](https://en.wikipedia.org/wiki/%22Hello,_World!%22_program) of machine learning. It contains 70,000 images of handwritten digits suitable for image classification. Typically, 60,000 of these images are used for training and 10,000 are set aside for testing. Each digit is a black and white 28 x 28 pixel image along with a label, so the full dataset can be used for supervised training as well as testing unsupervised algorithms.\n",
    "\n",
    "Over the years, MNIST has been used to measure the accuracy of a number of different algorithms. In this example, we will train a standard three layer neural network. Even this simple model can achieve 98% accuracy, rivaling human performance.\n",
    "\n",
    "This example requires Python 3, Keras, Tensorflow, matplotlib, and numpy. You can use either Tensorflow-CPU or Tensorflow-GPU, of course Tensorflow-GPU will train significantly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some configuration parameters and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The number of training samples per batch. 128 is a reasonable number.\n",
    "batch_size = 128\n",
    "\n",
    "# Our data set contains 10 digits, so the number of classes is 10\n",
    "num_classes = 10\n",
    "\n",
    "# epochs is the number of times the model is trained with the data set, more can be better, up to a point\n",
    "epochs = 5\n",
    "\n",
    "# dropout is a common regularization hyperperameter. It helps to avoid overfitting or memorizing the input.\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Keras has a builting function for loading MNIST data while splitting it into train and test sets. x_train and x_test are arrays if train and test input images respectively. Images are represented as a 28 x 28 matrix of pixel values. y_train and y_test are train and test labels respectively.\n",
    "\n",
    "The image matrices are reshaped into vectors suitable for training. Pixel values are normalized into values ranging from 0.0 - 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Save original test images for display later\n",
    "orig_test = x_test\n",
    "\n",
    "# Reshape and normalize data\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "\n",
    "This is the neural network model itself built using predefined Keras classes. This is a simple three layer model using dense, fully connected layers. Still, it achieves very good accuracy which demonstrates the predictive power of properly trained neural networks. The input shape to the model is an image represented as a 784 element (28 x 28) vector.\n",
    "\n",
    "The first two layers use a REctified Linear Unit activation function, which does not suffer from the \"vanishing gradient\" problem that plagued traditional sigmoid activation functions in the past. The output layer has 10 neurons corresponding to one of 10 possible digit classes. The neuron with the largest output is the most likely digit. This is known as one-hot encoding, a concept borrowed from digital logic.\n",
    "\n",
    "The best image recognition models use Convolutional Neural Networks (CNNs), which are like two dimensional weighted filters. The inpiration for CNNs comes from the visual cortex of animal brains. Models with over 100 CNN, pooling, padding, and other layers have been successfully trained to recognize complex objects as well as multiple objects in the one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create three layer model, two hidden layers, one output layer\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "# 10 output units, one for each digit (one hot encoding)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "This is more or less boilerplate Keras code to train the model given the training data set. Keras can also evaluate the trained model given the test data set. Matplotlib is used to plot train and test accuracy as a function of the epoch number.\n",
    "\n",
    "Ideally, the accuracy with test and train data should be about the same. Low training accuracy means the model exhibits high bias. High bias could be caused by a weak model, not enough training examples, or too few training epochs. High train accuracy and low test accuracy is a case of high variance. This means the model is more or less \"memorizing\" the expected output and not generalizing well. High variance can be reduced through *regularization*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "# Train model for a given number of epochs\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate model against test data\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "\n",
    "Use the trained model to make predictions on data that it was not trained on.\n",
    "Notice that prediction takes much less time compared with training.\n",
    "\n",
    "Keras can make predictions for a set of test data, rather than just one sample. In this case, the model is used to make predictions for all of the test data in one statement. Keras/Tensorflow will parallelize this operation as much as possible when using a GPU.\n",
    "\n",
    "The predicted output is a one-hot vector. argmax() is used to translate the output vector to a scalar value by choosing the index of the vector with the highest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test).argmax(1)\n",
    "y_test_values = y_test.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet chooses a random test image, prints the model predicted value, expected value (label), and the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = random.randrange(10000)\n",
    "plt.imshow(orig_test[index], cmap='gray')\n",
    "print('Prediction: %d, label: %d' % (predictions[index], y_test_values[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "The next snippet looks for model predictions that specifically do not match the expected value. In some cases, even humans might disagree on what this image is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10000):\n",
    "    index = random.randrange(10000)\n",
    "    if predictions[index] != y_test_values[index]:\n",
    "        break\n",
    "plt.imshow(orig_test[index], cmap='gray')\n",
    "print('Prediction: %d, label: %d' % (predictions[index], y_test_values[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet calculates the error rate by comparing predicted values with expected values. This is similar to what Keras does when evaluating a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0.0\n",
    "misclassified = 0.0\n",
    "for i in range(10000):\n",
    "    total += 1\n",
    "    if predictions[i] != y_test_values[i]:\n",
    "        misclassified += 1\n",
    "print('Error rate: %.2f %%' % (100.0*misclassified/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
